"""
–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è: GUI + —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∑—ã + —Ç—Ä–µ–∫–∏–Ω–≥ —à—Ç–∞–Ω–≥–∏
–° GUI –≤—ã–Ω–µ—Å–µ–Ω–Ω—ã–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
"""

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

import cv2
import numpy as np
import threading
import queue
import time
import socket
import json
import gc
import subprocess
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from typing import Optional, Tuple, List
from collections import deque
from urllib.parse import parse_qs, unquote
from PIL import ImageFont, ImageDraw, Image

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
import config
from pose_tracker import PoseTracker
from visualizer import Visualizer

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ GUI –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
from gui import AppGUI

# –ü–æ–ø—ã—Ç–∫–∞ NDI
try:
    import NDIlib as ndi
    NDI_AVAILABLE = True
except Exception:
    NDI_AVAILABLE = False

# –ü–æ–ø—ã—Ç–∫–∞ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –∫–∞–º–µ—Ä—ã
try:
    import pyvirtualcam
    from pyvirtualcam import PixelFormat
    VIRTUALCAM_AVAILABLE = True
except Exception:
    VIRTUALCAM_AVAILABLE = False

# MediaPipe
import mediapipe as mp
mp_pose = mp.solutions.pose

# -------------------- –£—Ç–∏–ª–∏—Ç—ã --------------------
def list_cameras(max_test=6):
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä —á–µ—Ä–µ–∑ OpenCV"""
    cams = []
    for i in range(max_test):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW if os.name == "nt" else 0)
        if cap and cap.isOpened():
            ret, _ = cap.read()
            if ret:
                cams.append(i)
            cap.release()
    return cams

def calculate_angle(a, b, c):
    """–†–∞—Å—á–µ—Ç —É–≥–ª–∞ –º–µ–∂–¥—É —Ç—Ä–µ–º—è —Ç–æ—á–∫–∞–º–∏"""
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba, bc = a - b, c - b
    denom = np.linalg.norm(ba) * np.linalg.norm(bc)
    if denom == 0:
        return 0.0
    cosang = np.dot(ba, bc) / denom
    return float(np.degrees(np.arccos(np.clip(cosang, -1.0, 1.0))))

def resize_with_aspect(frame, target_w, target_h):
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π"""
    h, w = frame.shape[:2]
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w*scale), int(h*scale)
    resized = cv2.resize(frame, (new_w, new_h))
    canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    x = (target_w - new_w)//2
    y = (target_h - new_h)//2
    canvas[y:y+new_h, x:x+new_w] = resized
    return canvas

# -------------------- OptimizedBarbellTracker (–∏–∑ main.py) --------------------
class OptimizedBarbellTracker:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä —à—Ç–∞–Ω–≥–∏"""
    
    def __init__(self, smoothing_factor=0.0):
        self.path = deque(maxlen=config.MAX_PATH_POINTS)
        self.last_position = None
        self.smoothed_position = None
        self.frames_without_detection = 0
        self.search_region = None
        self.smoothing_factor = smoothing_factor
        self.last_radius = None
        self.last_confidence = None
        self.last_detection_source = None
        self._kalman = None
        self._jitter_buffer = deque(maxlen=max(3, int(getattr(config, 'BARBELL_ANTI_JITTER_WINDOW', 3))))
        self._last_motion_ts = None
        self._last_motion_pos = None
    
    class _Kalman2D:
        """–ö–∞–ª–º–∞–Ω —Ñ–∏–ª—å—Ç—Ä –¥–ª—è 2D –ø–æ–∑–∏—Ü–∏–∏"""
        def __init__(self, x, y):
            self.dt = 1 / max(1, config.TARGET_FPS)
            self.x = np.array([[x], [y], [0.0], [0.0]], dtype=np.float32)
            self.F = np.array([[1, 0, self.dt, 0], [0, 1, 0, self.dt], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=np.float32)
            self.H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], dtype=np.float32)
            q, r = 2.0, 25.0
            self.Q = np.eye(4, dtype=np.float32) * q
            self.R = np.eye(2, dtype=np.float32) * r
            self.P = np.eye(4, dtype=np.float32) * 100.0
        
        def predict(self):
            self.x = self.F @ self.x
            self.P = self.F @ self.P @ self.F.T + self.Q
            return float(self.x[0, 0]), float(self.x[1, 0])
        
        def update(self, zx, zy):
            z = np.array([[zx], [zy]], dtype=np.float32)
            y = z - (self.H @ self.x)
            S = self.H @ self.P @ self.H.T + self.R
            K = self.P @ self.H.T @ np.linalg.inv(S)
            self.x = self.x + K @ y
            I = np.eye(self.P.shape[0], dtype=np.float32)
            self.P = (I - K @ self.H) @ self.P
            return float(self.x[0, 0]), float(self.x[1, 0])
    
    def update_search_region(self, left_wrist, right_wrist, frame_shape):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è —Ä—É–∫"""
        if left_wrist and right_wrist:
            min_x = min(left_wrist[0], right_wrist[0]) - 100
            max_x = max(left_wrist[0], right_wrist[0]) + 100
            min_y = min(left_wrist[1], right_wrist[1]) - 150
            max_y = max(left_wrist[1], right_wrist[1]) + 50
            h, w = frame_shape[:2]
            min_x, max_x = max(0, min_x), min(w, max_x)
            min_y, max_y = max(0, min_y), min(h, max_y)
            self.search_region = (int(min_x), int(min_y), int(max_x - min_x), int(max_y - min_y))
        else:
            self.search_region = None
    
    def detect_barbell(self, frame: np.ndarray, timestamp: float, debug_frame=None) -> Optional[Tuple[int, int]]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —à—Ç–∞–Ω–≥–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if config.BARBELL_USE_SEARCH_REGION and self.search_region:
            x, y, w, h = self.search_region
            roi = frame[y:y+h, x:x+w]
            if roi.size == 0:
                self.search_region = None
                return None
            if config.BARBELL_DEBUG_MODE and debug_frame is not None:
                cv2.rectangle(debug_frame, (x, y), (x+w, y+h), (255, 255, 0), 2)
        else:
            roi = frame
            x, y = 0, 0
        
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        if config.BARBELL_ENABLE_CLAHE:
            clahe = cv2.createCLAHE(clipLimit=config.BARBELL_CLAHE_CLIP_LIMIT, tileGridSize=config.BARBELL_CLAHE_TILE_GRID_SIZE)
            gray = clahe.apply(gray)
        
        median = cv2.medianBlur(gray, 5)
        blurred = cv2.GaussianBlur(median, (config.BARBELL_BLUR_SIZE, config.BARBELL_BLUR_SIZE), config.BARBELL_BLUR_SIGMA)
        
        circles = cv2.HoughCircles(
            blurred, cv2.HOUGH_GRADIENT,
            dp=config.BARBELL_CIRCLE_DP,
            minDist=config.BARBELL_CIRCLE_MIN_DIST,
            param1=config.BARBELL_CIRCLE_PARAM1,
            param2=config.BARBELL_CIRCLE_PARAM2,
            minRadius=config.BARBELL_CIRCLE_MIN_RADIUS,
            maxRadius=config.BARBELL_CIRCLE_MAX_RADIUS
        )
        detection_source = 'hough'
        
        if circles is not None:
            circles = np.round(circles[0, :]).astype("int")
            best_circle = self._select_best_circle(circles)
            
            if best_circle is not None:
                cx, cy, r = best_circle
                global_x = cx + x
                global_y = cy + y
                
                if not config.BARBELL_USE_KALMAN:
                    px, py = float(global_x), float(global_y)
                    if getattr(config, 'BARBELL_ANTI_JITTER_2TAP', True) and (self.smoothed_position or self.last_position):
                        prevx, prevy = (self.smoothed_position or self.last_position)
                        speed = np.hypot(px - prevx, py - prevy)
                        low = getattr(config, 'BARBELL_ANTI_JITTER_SPEED_THRESH_LOW', 2.0)
                        high = getattr(config, 'BARBELL_ANTI_JITTER_SPEED_THRESH_HIGH', 6.0)
                        w = float(getattr(config, 'BARBELL_ANTI_JITTER_2TAP_WEIGHT', 0.6))
                        if speed <= low:
                            px, py = float(prevx), float(prevy)
                        elif speed <= high:
                            px = w * px + (1 - w) * prevx
                            py = w * py + (1 - w) * prevy
                    self.smoothed_position = (px, py)
                else:
                    if self._kalman is None:
                        self._kalman = self._Kalman2D(global_x, global_y)
                    kx, ky = self._kalman.update(global_x, global_y)
                    if self.smoothed_position is None:
                        self.smoothed_position = (float(kx), float(ky))
                    else:
                        smooth_x = self.smoothing_factor * self.smoothed_position[0] + (1 - self.smoothing_factor) * kx
                        smooth_y = self.smoothing_factor * self.smoothed_position[1] + (1 - self.smoothing_factor) * ky
                        self.smoothed_position = (smooth_x, smooth_y)
                
                self.last_position = (global_x, global_y)
                self.frames_without_detection = 0
                self.last_radius = r
                self.last_confidence = 0.9
                self.last_detection_source = detection_source
                self.path.append((self.smoothed_position[0], self.smoothed_position[1], timestamp))
                return (int(self.smoothed_position[0]), int(self.smoothed_position[1]))
        
        self.frames_without_detection += 1
        if self.smoothed_position is not None and self.frames_without_detection < 5:
            if len(self.path) >= 2:
                prev_x, prev_y, _ = self.path[-1]
                return (int(prev_x), int(prev_y))
            return (int(self.smoothed_position[0]), int(self.smoothed_position[1]))
        return None
    
    def _select_best_circle(self, circles: np.ndarray) -> Optional[Tuple[int, int, int]]:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–π –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏"""
        if len(circles) == 0:
            return None
        if len(circles) == 1:
            return tuple(circles[0])
        if self.last_position is not None:
            best_circle = None
            best_score = -1
            last_x, last_y = self.last_position
            for circle in circles:
                cx, cy, r = circle
                dx, dy = float(cx - last_x), float(cy - last_y)
                gx = float(getattr(config, 'BARBELL_X_STABILITY_GAIN', 2.0))
                position_dist = np.sqrt((gx * dx)**2 + (dy)**2)
                position_score = 1.0 / (1.0 + position_dist / 100.0)
                if position_score > best_score:
                    best_score = position_score
                    best_circle = circle
            if best_circle is not None:
                return tuple(best_circle)
        if config.BARBELL_PREFER_LARGER_RADIUS:
            largest_idx = np.argmax([c[2] for c in circles])
            return tuple(circles[largest_idx])
        return tuple(circles[0])
    
    def get_path(self) -> List[Tuple[float, float, float]]:
        return list(self.path)
    
    def clear_path(self):
        self.path.clear()
        self.last_position = None
        self.smoothed_position = None
        self.frames_without_detection = 0

# -------------------- –ü–æ—Ç–æ–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ --------------------
class CaptureThread(threading.Thread):
    """–ü–æ—Ç–æ–∫ –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ"""
    def __init__(self, source, out_q, stop_event, target_fps=50):
        super().__init__(daemon=True)
        self.source = source
        self.out_q = out_q
        self.stop_event = stop_event
        self.target_fps = target_fps
        self.cap = None
        self.is_video_file = False
        self.video_fps = 50.0
        self.use_ffmpeg = False
        self.ffmpeg_process = None
        self.ffmpeg_width = getattr(config, "VIDEO_WIDTH", 1920)
        self.ffmpeg_height = getattr(config, "VIDEO_HEIGHT", 1080)
        self.ffmpeg_pixel_format = getattr(config, "DECKLINK_DEFAULT_PIXEL_FORMAT", "bgr24")
        self.ffmpeg_frame_size = self.ffmpeg_width * self.ffmpeg_height * 3
        self.ffmpeg_stderr_thread = None
        self.open_source(source)
    
    def open_source(self, source):
        # –ó–∞—Ö–≤–∞—Ç —á–µ—Ä–µ–∑ ffmpeg (DeckLink)
        if isinstance(source, str) and source.lower().startswith("decklink:"):
            try:
                self._start_decklink_capture(source)
            except Exception as e:
                self.use_ffmpeg = False
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å ffmpeg –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ '{source}': {e}")
            return
        
        # –û–±—ã—á–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª
        if isinstance(source, str) and source.lower().endswith((".mp4", ".mov", ".avi")):
            self.cap = cv2.VideoCapture(source)
            self.is_video_file = True
            # –ü–æ–ª—É—á–∞–µ–º FPS –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            if fps > 0:
                self.video_fps = fps
            else:
                self.video_fps = self.target_fps
            print(f"üìπ –í–∏–¥–µ–æ —Ñ–∞–π–ª –æ—Ç–∫—Ä—ã—Ç, FPS: {self.video_fps:.2f}")
            return
        
        # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å —á–∏—Å–ª–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å (DirectShow/Media Foundation)
        try:
            idx = int(source)
            self.is_video_file = False
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config
            target_width = getattr(config, "VIDEO_WIDTH", 1920)
            target_height = getattr(config, "VIDEO_HEIGHT", 1080)
            target_fps = getattr(config, "TARGET_FPS", 50)
            
            # –ü—Ä–æ–±—É–µ–º DirectShow —Å–Ω–∞—á–∞–ª–∞
            self.cap = cv2.VideoCapture(idx, cv2.CAP_DSHOW if os.name == "nt" else 0)
            
            if self.cap.isOpened():
                # –ü—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, target_width)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, target_height)
                self.cap.set(cv2.CAP_PROP_FPS, target_fps)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
                for _ in range(5):
                    ret, _ = self.cap.read()
                    if not ret:
                        break
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
                
                print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {idx} –æ—Ç–∫—Ä—ã—Ç–∞ —á–µ—Ä–µ–∑ DirectShow")
                print(f"   –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {actual_width}x{actual_height}, FPS: {actual_fps:.2f}")
            else:
                # –ï—Å–ª–∏ DirectShow –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º Media Foundation
                try:
                    self.cap = cv2.VideoCapture(idx, cv2.CAP_MSMF)
                    if self.cap.isOpened():
                        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, target_width)
                        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, target_height)
                        self.cap.set(cv2.CAP_PROP_FPS, target_fps)
                        
                        for _ in range(5):
                            ret, _ = self.cap.read()
                            if not ret:
                                break
                        
                        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
                        
                        print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {idx} –æ—Ç–∫—Ä—ã—Ç–∞ —á–µ—Ä–µ–∑ Media Foundation")
                        print(f"   –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {actual_width}x{actual_height}, FPS: {actual_fps:.2f}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Media Foundation –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        except Exception:
            self.cap = cv2.VideoCapture(source)
            self.is_video_file = False
        
        if not self.use_ffmpeg and (self.cap is None or not self.cap.isOpened()):
            print("‚ùå Cannot open source:", source)
    
    def _start_decklink_capture(self, source: str):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞—Ö–≤–∞—Ç–∞ —á–µ—Ä–µ–∑ ffmpeg —Å backend DeckLink"""
        self.use_ffmpeg = True
        self.is_video_file = False
        
        spec = source[len("decklink:"):]
        if "?" in spec:
            device_part, query_part = spec.split("?", 1)
            params = parse_qs(query_part, keep_blank_values=True)
        else:
            device_part = spec
            params = {}
        
        device_name = unquote(device_part).strip()
        if not device_name:
            device_name = getattr(config, "DECKLINK_DEFAULT_DEVICE", None)
        if not device_name:
            device_name = "0"
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Ç–æ–∫–∞
        self.ffmpeg_width = int(params.get("width", [getattr(config, "VIDEO_WIDTH", 1920)])[0])
        self.ffmpeg_height = int(params.get("height", [getattr(config, "VIDEO_HEIGHT", 1080)])[0])
        fps_param = params.get("fps") or params.get("framerate")
        ffmpeg_fps = None
        if fps_param:
            try:
                ffmpeg_fps = float(fps_param[0])
            except (ValueError, TypeError):
                ffmpeg_fps = None
        format_code = params.get("format_code", [getattr(config, "DECKLINK_DEFAULT_FORMAT_CODE", None)])[0]
        
        pixel_format = params.get("pix_fmt", [getattr(config, "DECKLINK_DEFAULT_PIXEL_FORMAT", "bgr24")])[0]
        pixel_format = (pixel_format or "bgr24").lower()
        if pixel_format != "bgr24":
            print(f"‚ö†Ô∏è –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥ bgr24. –ó–∞–ø—Ä–æ—à–µ–Ω '{pixel_format}', –∏—Å–ø–æ–ª—å–∑—É—é 'bgr24'.")
            pixel_format = "bgr24"
        self.ffmpeg_pixel_format = pixel_format
        self.ffmpeg_frame_size = self.ffmpeg_width * self.ffmpeg_height * 3
        
        ffmpeg_path = getattr(config, "FFMPEG_PATH", "ffmpeg")
        cmd = [
            ffmpeg_path,
            "-hide_banner",
            "-loglevel", "error",
            "-nostdin",
            "-thread_queue_size", "2048",
            "-f", "decklink",
        ]
        if format_code:
            cmd.extend(["-format_code", format_code])
        if ffmpeg_fps:
            cmd.extend(["-framerate", str(ffmpeg_fps)])
        cmd.extend(["-i", device_name])
        cmd.extend([
            "-pix_fmt", pixel_format,
            "-vsync", "0",
            "-f", "rawvideo",
            "-"
        ])
        
        try:
            self.ffmpeg_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                bufsize=0
            )
        except FileNotFoundError:
            raise RuntimeError(f"FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ '{ffmpeg_path}'. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–±–æ—Ä–∫—É —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π DeckLink.")
        except Exception as exc:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ FFmpeg: {exc}")
        
        self.ffmpeg_stderr_thread = threading.Thread(target=self._consume_ffmpeg_stderr, daemon=True)
        self.ffmpeg_stderr_thread.start()
        fps_info = ffmpeg_fps if ffmpeg_fps else getattr(config, "TARGET_FPS", 30)
        print(f"üé• FFmpeg DeckLink: '{device_name}' -> {self.ffmpeg_width}x{self.ffmpeg_height}@{fps_info}fps")
    
    def _consume_ffmpeg_stderr(self):
        """–í—ã–≤–æ–¥ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π ffmpeg, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø–æ–ª–Ω—è–ª—Å—è –±—É—Ñ–µ—Ä stderr"""
        if not self.ffmpeg_process or self.ffmpeg_process.stderr is None:
            return
        try:
            for raw_line in self.ffmpeg_process.stderr:
                if not raw_line:
                    break
                try:
                    line = raw_line.decode("utf-8", "ignore").strip()
                except Exception:
                    line = str(raw_line).strip()
                if line:
                    print(f"[ffmpeg] {line}")
        except Exception:
            pass
    
    def _cleanup_capture(self):
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –∑–∞—Ö–≤–∞—Ç–∞"""
        if self.use_ffmpeg:
            if self.ffmpeg_process:
                try:
                    if self.ffmpeg_process.stdout:
                        self.ffmpeg_process.stdout.close()
                    if self.ffmpeg_process.stderr:
                        self.ffmpeg_process.stderr.close()
                except Exception:
                    pass
                try:
                    self.ffmpeg_process.terminate()
                    self.ffmpeg_process.wait(timeout=2.0)
                except Exception:
                    try:
                        self.ffmpeg_process.kill()
                    except Exception:
                        pass
            self.ffmpeg_process = None
        else:
            try:
                if self.cap:
                    self.cap.release()
            except Exception:
                pass
        self.cap = None
    def run(self):
        frame_time = 1.0 / self.video_fps if self.is_video_file else 1.0 / max(self.target_fps, 1)
        last_frame_time = time.time()
        
        try:
            while not self.stop_event.is_set():
                if self.use_ffmpeg:
                    if not self.ffmpeg_process or self.ffmpeg_process.stdout is None:
                        if self.ffmpeg_process and self.ffmpeg_process.poll() is not None:
                            print("‚ùå FFmpeg DeckLink: –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è")
                            break
                        time.sleep(0.05)
                        continue
                    
                    data = self.ffmpeg_process.stdout.read(self.ffmpeg_frame_size)
                    if not data or len(data) < self.ffmpeg_frame_size:
                        if self.stop_event.is_set():
                            break
                        if self.ffmpeg_process and self.ffmpeg_process.poll() is not None:
                            print("‚ùå FFmpeg DeckLink: –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                            break
                        time.sleep(0.01)
                        continue
                    
                    frame = np.frombuffer(data, dtype=np.uint8)
                    try:
                        frame = frame.reshape((self.ffmpeg_height, self.ffmpeg_width, 3))
                    except ValueError:
                        # –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞
                        print("‚ö†Ô∏è FFmpeg DeckLink: –†–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º")
                        time.sleep(0.01)
                        continue
                else:
                    if self.cap is None or not self.cap.isOpened():
                        time.sleep(0.05)
                        continue
                    
                    if self.is_video_file:
                        elapsed = time.time() - last_frame_time
                        if elapsed < frame_time:
                            time.sleep(frame_time - elapsed)
                        last_frame_time = time.time()
                    
                    ret, frame = self.cap.read()
                    if not ret:
                        if self.is_video_file:
                            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                            last_frame_time = time.time()
                            continue
                        time.sleep(0.02)
                        continue
                
                try:
                    self.out_q.put(frame, block=False)
                except queue.Full:
                    try:
                        _ = self.out_q.get_nowait()
                        self.out_q.put(frame, block=False)
                    except Exception:
                        pass
        finally:
            self._cleanup_capture()

class ProcThread(threading.Thread):
    """–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (MediaPipe + —Ç—Ä–µ–∫–∏–Ω–≥ —à—Ç–∞–Ω–≥–∏)"""
    def __init__(self, in_q, out_q, stop_event, proc_w, proc_h, every_n, pose_tracker, barbell_tracker, enable_barbell):
        super().__init__(daemon=True)
        self.in_q = in_q
        self.out_q = out_q
        self.stop_event = stop_event
        self.proc_w = proc_w
        self.proc_h = proc_h
        self.every_n = every_n
        self.idx = 0
        self.pose_tracker = pose_tracker
        self.barbell_tracker = barbell_tracker
        self.enable_barbell = enable_barbell
    
    def run(self):
        while not self.stop_event.is_set():
            try:
                frame = self.in_q.get(timeout=0.05)
            except queue.Empty:
                time.sleep(0.01)
                continue
            
            self.idx += 1
            timestamp = time.time()
            pose_data = None
            barbell_pos = None
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∑—ã
            if self.pose_tracker and self.idx % self.every_n == 0:
                pose_data = self.pose_tracker.process_frame(frame)
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ —à—Ç–∞–Ω–≥–∏
                if self.enable_barbell and pose_data and config.BARBELL_USE_SEARCH_REGION and pose_data.get('all_landmarks'):
                    lm = pose_data['all_landmarks']
                    h, w = frame.shape[:2]
                    LEFT_WRIST, RIGHT_WRIST = 15, 16
                    left_wrist_px = None
                    right_wrist_px = None
                    if lm[LEFT_WRIST].visibility > 0.5:
                        left_wrist_px = (int(lm[LEFT_WRIST].x * w), int(lm[LEFT_WRIST].y * h))
                    if lm[RIGHT_WRIST].visibility > 0.5:
                        right_wrist_px = (int(lm[RIGHT_WRIST].x * w), int(lm[RIGHT_WRIST].y * h))
                    if left_wrist_px or right_wrist_px:
                        self.barbell_tracker.update_search_region(left_wrist_px, right_wrist_px, frame.shape)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —à—Ç–∞–Ω–≥–∏
            if self.enable_barbell:
                barbell_pos = self.barbell_tracker.detect_barbell(frame, timestamp)
            
            try:
                self.out_q.put((frame, pose_data, barbell_pos, timestamp), block=False)
            except queue.Full:
                try:
                    _ = self.out_q.get_nowait()
                    self.out_q.put((frame, pose_data, barbell_pos, timestamp), block=False)
                except:
                    pass

# -------------------- –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–∫–µ–ª–µ—Ç–∞ --------------------
def draw_overlay(frame, landmarks, angles, bone_color, joint_color, bone_width, joint_radius, font_size=0.7, font_thickness=1):
    """–†–∏—Å—É–µ—Ç —Å–∫–µ–ª–µ—Ç —Å —É–≥–ª–∞–º–∏"""
    if landmarks is None:
        return frame
    h, w = frame.shape[:2]
    overlay = frame.copy()
    
    limbs = {
        "left_arm": (11, 13, 15),
        "right_arm": (12, 14, 16),
        "left_leg": (23, 25, 27),
        "right_leg": (24, 26, 28),
    }
    
    bone_bgr = tuple(int(bone_color[i:i+2], 16) for i in (5, 3, 1))
    joint_bgr = tuple(int(joint_color[i:i+2], 16) for i in (5, 3, 1))
    
    for limb, (a, b, c) in limbs.items():
        try:
            pa = (int(landmarks[a].x * w+480), int(landmarks[a].y * h))
            pb = (int(landmarks[b].x * w+480), int(landmarks[b].y * h))
            pc = (int(landmarks[c].x * w+480), int(landmarks[c].y * h))
        except:
            continue
        
        outline_width = bone_width + 2
        cv2.line(overlay, pa, pb, (0, 0, 0), outline_width, cv2.LINE_AA)
        cv2.line(overlay, pb, pc, (0, 0, 0), outline_width, cv2.LINE_AA)
        cv2.line(overlay, pa, pb, bone_bgr, bone_width, cv2.LINE_AA)
        cv2.line(overlay, pb, pc, bone_bgr, bone_width, cv2.LINE_AA)
        
        angle_val = angles.get(limb, 0.0)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —à—Ä–∏—Ñ—Ç–∞ –∏–∑ GUI
        outline_thickness = max(2, font_thickness)  # –û–±–≤–æ–¥–∫–∞ —Ç–æ–ª—â–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        
        # –†–∏—Å—É–µ–º –æ–±–≤–æ–¥–∫—É —Ç–µ–∫—Å—Ç–∞
        # cv2.putText(overlay, f"{angle_val:.0f}", (pb[0] + 10, pb[1] - 10),
                   # cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 0), outline_thickness, cv2.LINE_AA)



        image_pil = Image.fromarray(cv2.cvtColor(overlay, cv2.COLOR_BGRA2RGB))
        draw = ImageDraw.Draw(image_pil)
        font = ImageFont.truetype("arial.ttf",font_size*50) if hasattr(ImageFont, 'truetype') else ImageFont.load_default()
        if outline_thickness > 1:
            for dx in [-outline_thickness, 0, outline_thickness]:
                for dy in [-outline_thickness, 0, outline_thickness]:
                    if dx != 0 or dy != 0:
                        draw.text((pb[0] + 10 + 100, pb[1] - 10), f"{angle_val:.0f}¬∞", font=font, fill=(255,255,255))
        draw.text((pb[0] +10 + 100, pb[1] - 10), f"{angle_val:.0f}¬∞", font=font, fill=(255,255,255))   
        overlay  = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
        # ¬∞
        # –†–∏—Å—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        # cv2.putText(overlay, f"{angle_val:.0f}", (pb[0] + 10, pb[1] - 10),
          #          cv2.FONT_HERSHEY_SIMPLEX, font_size, bone_bgr, font_thickness, cv2.LINE_AA)
        
        for idx in [a, b, c]:
            x, y = int(landmarks[idx].x * w), int(landmarks[idx].y * h)
            cv2.circle(overlay, (x+480, y), joint_radius + 2, (0, 0, 0), -1, cv2.LINE_AA)
            cv2.circle(overlay, (x+480, y), joint_radius, joint_bgr, -1, cv2.LINE_AA)
    
    return cv2.addWeighted(overlay, 0.9, frame, 0.1, 0)
# -------------------- –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è --------------------
class UnifiedTrackingApp:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Unified Pose & Barbell Tracking")
        # –†–∞–∑–º–µ—Ä—ã –æ–∫–Ω–∞
        window_width = 1200
        window_height = 1100
        
        screen_width = self.root.winfo_screenwidth()
        screen_height = self.root.winfo_screenheight()
        
        x = (screen_width - window_width) // 2
        y = (screen_height - window_height) // 2
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–µ–æ–º–µ—Ç—Ä–∏—é —Å –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        self.root.geometry(f"{window_width}x{window_height}+{x}+{y}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞–º–µ—Ä
        self.camera_list = list_cameras()
    
        
        # –°–æ–∑–¥–∞–µ–º GUI
        self.gui = AppGUI(self.root, self.camera_list)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callbacks
        self.gui.set_start_callback(self.start_processing)
        self.gui.set_stop_callback(self.stop_processing)
        self.gui.set_quit_callback(self.quit_app)
        self.gui.set_refresh_cameras_callback(self.refresh_cameras)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        self.running = False
        self.stop_event = threading.Event()
        
        # –ü–æ—Ç–æ–∫–∏ –∏ –æ—á–µ—Ä–µ–¥–∏
        self.cap_thread = None
        self.proc_thread = None
        self.render_thread = None
        self.proc_q = None
        self.render_q = None
        
        # –¢—Ä–µ–∫–µ—Ä—ã
        self.pose_tracker = None
        self.barbell_tracker = None
        self.visualizer = None
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥—ã
        self.ndi_sender = None
        self.virtual_cam = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–∫–Ω–∞
        self.WINDOW_W = 1920
        self.WINDOW_H = 1080
        
        # –£–≥–ª–æ–≤–æ–π –±—É—Ñ–µ—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.angle_buffer = {k: [] for k in ["left_arm","right_arm","left_leg","right_leg"]}
        
        # UDP
        try:
            self.ue_ip, self.ue_port = config.UDP_HOST, config.UDP_PORT
        except:
            self.ue_ip, self.ue_port = "127.0.0.1", 5005
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞
        self.root.protocol("WM_DELETE_WINDOW", self.quit_app)
        
    def refresh_cameras(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–∞–º–µ—Ä"""
        self.camera_list = list_cameras()
        self.gui.update_camera_list(self.camera_list)
        
    def start_processing(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        if self.running:
            return
            
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ GUI
            source = self.gui.get_source()
            proc_w, proc_h, every_n, target_fps = self.gui.get_processing_params()
            
        except ValueError as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", str(e))
            return
            
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–æ–≤
        self.gui.update_status("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
        
        # –¢—Ä–µ–∫–µ—Ä –ø–æ–∑—ã
        if self.gui.enable_pose.get():
            self.pose_tracker = PoseTracker(
                min_detection_confidence=self.gui.min_det.get(),
                min_tracking_confidence=self.gui.min_track.get()
            )
            
        # –¢—Ä–µ–∫–µ—Ä —à—Ç–∞–Ω–≥–∏
        if self.gui.enable_barbell.get():
            self.barbell_tracker = OptimizedBarbellTracker(smoothing_factor=config.BARBELL_SMOOTHING_FACTOR)
            
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        if self.gui.enable_barbell.get() or self.gui.enable_pose.get():
            self.visualizer = Visualizer(pose_tracker=self.pose_tracker if self.gui.enable_pose.get() else None)
            
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–µ–π –∏ –ø–æ—Ç–æ–∫–æ–≤
        self.proc_q = queue.Queue(maxsize=2)
        self.render_q = queue.Queue(maxsize=2)
        self.stop_event.clear()
        
        # –ü–æ—Ç–æ–∫ –∑–∞—Ö–≤–∞—Ç–∞
        self.cap_thread = CaptureThread(source, self.proc_q, self.stop_event, target_fps)
        
        # –ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.proc_thread = ProcThread(
            self.proc_q, self.render_q, self.stop_event, proc_w, proc_h, every_n,
            self.pose_tracker, self.barbell_tracker, self.gui.enable_barbell.get()
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏
        self.cap_thread.start()
        self.proc_thread.start()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤
        self._initialize_outputs()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.running = True
        self.gui.set_running_state(True)
        self.gui.update_status("–°—Ç—Ä–∏–º–∏–Ω–≥ –∞–∫—Ç–∏–≤–µ–Ω")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞
        self.render_thread = threading.Thread(target=self._render_loop, daemon=True)
        self.render_thread.start()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏
        self._show_hotkeys()
        
    def stop_processing(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        if not self.running:
            return
            
        self.stop_event.set()
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏
        if self.cap_thread:
            self.cap_thread.join(timeout=1.0)
        if self.proc_thread:
            self.proc_thread.join(timeout=1.0)
            
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥—ã
        self._cleanup_outputs()
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã —Ç—Ä–µ–∫–µ—Ä–æ–≤
        if self.pose_tracker:
            self.pose_tracker.release()
            
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.running = False
        self.gui.set_running_state(False)
        self.gui.update_status("–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
        self.gui.preview_label.configure(
            text="–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ç—Ä–∏–º –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            image=''
        )
        
        gc.collect()
        
    def _initialize_outputs(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤ (NDI, VirtualCam)"""
        # NDI
        if self.gui.use_ndi.get() and NDI_AVAILABLE:
            try:
                if ndi.initialize():
                    sc = ndi.SendCreate()
                    sc.ndi_name = self.gui.ndi_name.get()
                    self.ndi_sender = ndi.send_create(sc)
            except Exception as e:
                messagebox.showwarning("NDI", f"NDI init error: {e}")
                
        # Virtual Camera
        if self.gui.use_virtual.get() and VIRTUALCAM_AVAILABLE:
            try:
                self.virtual_cam = pyvirtualcam.Camera(
                    width=self.WINDOW_W, 
                    height=self.WINDOW_H,
                    fps=50,
                    fmt=PixelFormat.BGR
                )
            except Exception as e:
                messagebox.showwarning("VirtualCam", f"Error: {e}")
                
    def _cleanup_outputs(self):
        """–û—á–∏—Å—Ç–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤"""
        # NDI
        try:
            if self.ndi_sender:
                ndi.send_destroy(self.ndi_sender)
                ndi.destroy()
                self.ndi_sender = None
        except:
            pass
            
        # Virtual Camera
        try:
            if self.virtual_cam:
                self.virtual_cam.close()
                self.virtual_cam = None
        except:
            pass
            
    def _show_hotkeys(self):
        """–ü–æ–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à–∞—Ö"""
        print("\n" + "="*50)
        print("üéÆ –ì–û–†–Ø–ß–ò–ï –ö–õ–ê–í–ò–®–ò (–≤ –æ–∫–Ω–µ OpenCV):")
        print("  'q' –∏–ª–∏ ESC - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
        print("  'c' - –æ—á–∏—Å—Ç–∏—Ç—å –ø—É—Ç—å —à—Ç–∞–Ω–≥–∏")
        print("  '1' - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∑—ã")
        print("  '2' - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ —à—Ç–∞–Ω–≥–∏")
        print("="*50 + "\n")
        
    def _render_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞"""
        last_frame = np.zeros((self.WINDOW_H, self.WINDOW_W, 3), dtype=np.uint8)
        last_pose_data = None
        last_barbell_pos = None
        last_send = 0.0
        frame_counter = 0
        LEFT_WRIST, RIGHT_WRIST = 15, 16
        
        while not self.stop_event.is_set():
            frame_counter += 1
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                frame, pose_data, barbell_pos, timestamp = self.render_q.get(timeout=0.05)
                last_frame = frame.copy()
                last_pose_data = pose_data
                last_barbell_pos = barbell_pos
            except queue.Empty:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞
                frame, pose_data, barbell_pos, timestamp = last_frame, last_pose_data, last_barbell_pos, time.time()
                
            display_frame = frame.copy()
            angles = {}
            left_knee_coords = None
            right_knee_coords = None
            left_knee_angle = None
            right_knee_angle = None
            joints_data = {}
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∑—ã
            if self.gui.enable_pose.get() and pose_data and pose_data.get('all_landmarks'):
                lm = pose_data['all_landmarks']
                h, w = frame.shape[:2]
                
                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–æ–≤
                try:
                    angles["left_arm"] = calculate_angle((lm[11].x,lm[11].y),(lm[13].x,lm[13].y),(lm[15].x,lm[15].y))
                    angles["right_arm"] = calculate_angle((lm[12].x,lm[12].y),(lm[14].x,lm[14].y),(lm[16].x,lm[16].y))
                    angles["left_leg"] = calculate_angle((lm[23].x,lm[23].y),(lm[25].x,lm[25].y),(lm[27].x,lm[27].y))
                    angles["right_leg"] = calculate_angle((lm[24].x,lm[24].y),(lm[26].x,lm[26].y),(lm[28].x,lm[28].y))
                except:
                    angles = {}
                
                # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —É–≥–ª–æ–≤
                for k,v in angles.items():
                    buf = self.angle_buffer.get(k, [])
                    buf.append(v)
                    if len(buf) > 5:
                        buf.pop(0)
                    self.angle_buffer[k] = buf
                    angles[k] = sum(buf)/len(buf) if buf else v
                
                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–∫–µ–ª–µ—Ç–∞
                if self.gui.show_joints.get():
                    font_settings = self.gui.get_font_settings()
                    display_frame = draw_overlay(
                        display_frame, lm, angles, 
                        self.gui.bone_color.get(), 
                        self.gui.joint_color.get(),
                        self.gui.bone_width.get(), 
                        self.gui.joint_radius.get(),
                        font_size=font_settings['font_size'],
                        font_thickness=font_settings['font_thickness']
                    )
                
                # –î–∞–Ω–Ω—ã–µ –¥–ª—è UDP
                if pose_data.get('all_landmarks'):
                    joints_data = {str(i): [float(l.x), float(l.y), float(getattr(l, 'z', 0.0))]
                                 for i, l in enumerate(lm)}
                    joints = self.pose_tracker.get_leg_joints(pose_data) if self.pose_tracker else {}
                    left_knee_coords = joints.get('left_knee')
                    right_knee_coords = joints.get('right_knee')
                    left_knee_angle = joints.get('left_knee_angle')
                    right_knee_angle = joints.get('right_knee_angle')
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏ —à—Ç–∞–Ω–≥–∏
            if self.gui.enable_barbell.get() and self.barbell_tracker and self.visualizer:
                display_frame = self.visualizer.draw_frame(
                    display_frame, 
                    pose_data if self.gui.enable_pose.get() else None,
                    barbell_pos, 
                    self.barbell_tracker.get_path()
                )
            elif self.gui.enable_barbell.get() and self.barbell_tracker:
                # –ï—Å–ª–∏ visualizer –Ω–µ —Å–æ–∑–¥–∞–Ω, —Ä–∏—Å—É–µ–º –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é
                path = self.barbell_tracker.get_path()
                if len(path) >= 2:
                    for i in range(1, len(path)):
                        pt1 = (int(path[i-1][0]), int(path[i-1][1]))
                        pt2 = (int(path[i][0]), int(path[i][1]))
                        cv2.line(display_frame, pt1, pt2, config.COLOR_BARBELL_PATH, config.LINE_THICKNESS)
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ UDP –¥–∞–Ω–Ω—ã—Ö
            udp_data = {
                "timestamp": timestamp,
                "barbell": {
                    "position": [int(barbell_pos[0]), int(barbell_pos[1])] if barbell_pos else None,
                    "confidence": float(self.barbell_tracker.last_confidence) if (self.barbell_tracker and self.barbell_tracker.last_confidence) else None,
                    "source": self.barbell_tracker.last_detection_source if self.barbell_tracker else None
                },
                "knee_positions": {
                    "left_knee": list(left_knee_coords) if left_knee_coords else None,
                    "right_knee": list(right_knee_coords) if right_knee_coords else None,
                    "left_knee_angle": float(left_knee_angle) if left_knee_angle else None,
                    "right_knee_angle": float(right_knee_angle) if right_knee_angle else None
                },
                "joints": joints_data,
                "barbell_path": [
                    {"x": float(x), "y": float(y), "timestamp": float(ts)}
                    for x, y, ts in (self.barbell_tracker.get_path() if self.barbell_tracker else [])
                ],
                "angles": {k: round(v,2) for k,v in angles.items()} if angles else {}
            }
            try:
                self.sock.sendto(json.dumps(udp_data, ensure_ascii=False).encode('utf-8'), (self.ue_ip, self.ue_port))
            except:
                pass
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
            if display_frame.shape[1] != self.WINDOW_W or display_frame.shape[0] != self.WINDOW_H:
                display_frame = resize_with_aspect(display_frame, self.WINDOW_W, self.WINDOW_H)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            self.root.after(0, self.gui.update_preview, display_frame.copy())
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.imshow("Unified Tracking (ESC to stop)", display_frame)
            
            # –í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –∫–∞–º–µ—Ä–∞
            if self.virtual_cam:
                try:
                    self.virtual_cam.send(display_frame)
                    self.virtual_cam.sleep_until_next_frame()
                except:
                    pass
            
            # NDI
            if self.ndi_sender:
                now = time.time()
                if now - last_send >= 1.0 / 120:  # 30 FPS –¥–ª—è NDI
                    try:
                        bgrx = np.zeros((self.WINDOW_H, self.WINDOW_W, 4), dtype=np.uint8)
                        bgrx[:, :, :3] = display_frame
                        vf = ndi.VideoFrameV2()
                        vf.data = bgrx
                        vf.xres = self.WINDOW_W
                        vf.yres = self.WINDOW_H
                        vf.FourCC = ndi.FOURCC_VIDEO_TYPE_BGRX
                        ndi.send_send_video_v2(self.ndi_sender, vf)
                    except Exception as e:
                        if frame_counter % 300 == 0:
                            print("NDI send error:", e)
                    last_send = now
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à
            k = cv2.waitKey(1) & 0xFF
            if k == 27 or k == ord('q'):  # ESC –∏–ª–∏ 'q' - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
                self.stop_processing()
                break
            elif k == ord('c') or k == ord('C'):  # 'c' - –æ—á–∏—Å—Ç–∏—Ç—å –ø—É—Ç—å —à—Ç–∞–Ω–≥–∏
                if self.barbell_tracker:
                    self.barbell_tracker.clear_path()
                    print("–ü—É—Ç—å —à—Ç–∞–Ω–≥–∏ –æ—á–∏—â–µ–Ω")
            elif k == ord('1'):  # '1' - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∑—ã
                self.gui.enable_pose.set(not self.gui.enable_pose.get())
                print(f"–¢—Ä–µ–∫–∏–Ω–≥ –ø–æ–∑—ã: {'–í–ö–õ' if self.gui.enable_pose.get() else '–í–´–ö–õ'}")
            elif k == ord('2'):  # '2' - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ —à—Ç–∞–Ω–≥–∏
                self.gui.enable_barbell.set(not self.gui.enable_barbell.get())
                print(f"–¢—Ä–µ–∫–∏–Ω–≥ —à—Ç–∞–Ω–≥–∏: {'–í–ö–õ' if self.gui.enable_barbell.get() else '–í–´–ö–õ'}")
        
        try:
            cv2.destroyAllWindows()
        except:
            pass
        
    def quit_app(self):
        """–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        if self.running:
            if not messagebox.askyesno("–í—ã—Ö–æ–¥", "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∏–º–∏–Ω–≥ –∏ –≤—ã–π—Ç–∏?"):
                return
            self.stop_processing()
            
        self.root.quit()
        self.root.destroy()
        
    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        self.root.mainloop()

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""
    app = UnifiedTrackingApp()
    app.run()

if __name__ == "__main__":
    main()